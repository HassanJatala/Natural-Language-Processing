{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71c01ff-17e4-429d-9640-ced97c6b7f7a",
   "metadata": {},
   "source": [
    "# Question #01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ce110e-f1f7-43a9-be3b-4d0ae59447e8",
   "metadata": {},
   "source": [
    "## Downloading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be42c8be-ec2a-432c-b227-d370c184009f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Tech\n",
      "[nltk_data]     Mehal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Tech\n",
      "[nltk_data]     Mehal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Tech\n",
      "[nltk_data]     Mehal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Tech Mehal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6c018d-a6cf-46ca-9426-4497751429ca",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad381f8-0081-4608-901e-9fc075e3b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a1987-77a4-4a42-8485-cb0e8307cc90",
   "metadata": {},
   "source": [
    "## LOWER CASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72abd2b-b49b-4ecd-bf1a-603f86109605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "I AM Loving the NLP Class!!! But sometimes, it Feels very CONFUSING !!!\n",
      "\n",
      "After Lowercasing:\n",
      "i am loving the nlp class!!! but sometimes, it feels very confusing !!!\n"
     ]
    }
   ],
   "source": [
    "text = \"I AM Loving the NLP Class!!! But sometimes, it Feels very CONFUSING !!!\"\n",
    "print(\"Original Text:\")\n",
    "print(text)\n",
    "\n",
    "text = text.lower()\n",
    "print(\"\\nAfter Lowercasing:\")\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c6414-64df-4e39-b9de-64791936aae7",
   "metadata": {},
   "source": [
    "## Stemming And Lemitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc1f63d9-d7ac-41f8-a307-15a24e98046c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stemming Result:\n",
      "['i', 'am', 'love', 'the', 'nlp', 'but', 'it', 'feel', 'veri', 'confus']\n",
      "\n",
      "Lemmatization Result:\n",
      "['i', 'am', 'loving', 'the', 'nlp', 'but', 'it', 'feel', 'very', 'confusing']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = text.split()\n",
    "stemmed = [ps.stem(w) for w in words if w.isalpha()]\n",
    "lemmatized = [lemmatizer.lemmatize(w) for w in words if w.isalpha()]\n",
    "print(\"\\nStemming Result:\")\n",
    "print(stemmed)\n",
    "print(\"\\nLemmatization Result:\")\n",
    "print(lemmatized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddcf504-66b6-48a4-8cb0-89b2e6b4827d",
   "metadata": {},
   "source": [
    "## StopWord Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0031153f-00b9-4e90-a3de-9520aa1d74b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After stopword removal:\n",
      "['loving', 'nlp', 'feel', 'confusing']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered = [w for w in lemmatized if w not in stop_words]\n",
    "print(\"\\nAfter stopword removal:\")\n",
    "print(filtered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de3b780-3b5e-4c8a-86a2-3e52bec7e50f",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "302ee277-379f-4e67-b5f7-7cf591dacae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Tokenization:\n",
      "['i', 'am', 'loving', 'the', 'nlp', 'class', '!', '!', '!', 'but', 'sometimes', ',', 'it', 'feels', 'very', 'confusing', '!', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "print(\"\\nAfter Tokenization:\")\n",
    "print(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3121c145-6517-4a56-ab92-8b13bea5ea34",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183e2fe8-2b2b-4efb-9e2b-5815425a8744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "POS Tagging:\n",
      "[('i', 'NN'), ('am', 'VBP'), ('loving', 'VBG'), ('the', 'DT'), ('nlp', 'JJ'), ('class', 'NN'), ('!', '.'), ('!', '.'), ('!', '.'), ('but', 'CC'), ('sometimes', 'RB'), (',', ','), ('it', 'PRP'), ('feels', 'VBZ'), ('very', 'RB'), ('confusing', 'JJ'), ('!', '.'), ('!', '.'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(\"\\nPOS Tagging:\")\n",
    "print(pos_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bdb25d-5564-4c71-82c4-fd98e2484422",
   "metadata": {},
   "source": [
    "# Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2f756e-a174-49be-b5fc-07efa60360d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d91baf8-ba2e-4900-a8ae-bf740437a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"I am loving the NLP class, but sometimes it feels confusing!!!\",\n",
    "    \"NLP is a fascinating field — it deals with text, speech, and language understanding.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed92ae0d-9033-4a74-888c-19129e3273d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 10)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 19)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 15)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 18)\t1\n"
     ]
    }
   ],
   "source": [
    "Vectorizer=CountVectorizer()\n",
    "bow=Vectorizer.fit_transform(corpus)\n",
    "print(bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d63dcbe-c53e-4a0a-9ec3-0910784edc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "{'am': 0, 'loving': 12, 'the': 17, 'nlp': 13, 'class': 3, 'but': 2, 'sometimes': 14, 'it': 10, 'feels': 7, 'confusing': 4, 'is': 9, 'fascinating': 6, 'field': 8, 'deals': 5, 'with': 19, 'text': 16, 'speech': 15, 'and': 1, 'language': 11, 'understanding': 18}\n"
     ]
    }
   ],
   "source": [
    "print(\"************************\")\n",
    "vocab=Vectorizer.vocabulary_\n",
    "print(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7563e10-eb3c-4760-b544-452c5cfd0c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bag of words \n",
      "[[1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0]\n",
      " [0 1 0 0 0 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nbag of words \")\n",
    "print(bow.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af88c9-2c5e-4eef-9c86-ecb82a953e38",
   "metadata": {},
   "source": [
    "# Tf-Idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8479696d-d601-4bab-863f-aceaa7f45a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"I am loving the NLP class, but sometimes it feels confusing!!!\",\n",
    "    \"NLP is a fascinating field — it deals with text, speech, and language understanding.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a8df433-a06b-4c1d-a698-ce33feb50169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.3331023155662109\n",
      "  (0, 12)\t0.3331023155662109\n",
      "  (0, 17)\t0.3331023155662109\n",
      "  (0, 13)\t0.23700504099641823\n",
      "  (0, 3)\t0.3331023155662109\n",
      "  (0, 2)\t0.3331023155662109\n",
      "  (0, 14)\t0.3331023155662109\n",
      "  (0, 10)\t0.23700504099641823\n",
      "  (0, 7)\t0.3331023155662109\n",
      "  (0, 4)\t0.3331023155662109\n",
      "  (1, 13)\t0.2144061353375654\n",
      "  (1, 10)\t0.2144061353375654\n",
      "  (1, 9)\t0.3013403421812651\n",
      "  (1, 6)\t0.3013403421812651\n",
      "  (1, 8)\t0.3013403421812651\n",
      "  (1, 5)\t0.3013403421812651\n",
      "  (1, 19)\t0.3013403421812651\n",
      "  (1, 16)\t0.3013403421812651\n",
      "  (1, 15)\t0.3013403421812651\n",
      "  (1, 1)\t0.3013403421812651\n",
      "  (1, 11)\t0.3013403421812651\n",
      "  (1, 18)\t0.3013403421812651\n",
      "***************\n",
      "['am' 'and' 'but' 'class' 'confusing' 'deals' 'fascinating' 'feels'\n",
      " 'field' 'is' 'it' 'language' 'loving' 'nlp' 'sometimes' 'speech' 'text'\n",
      " 'the' 'understanding' 'with']\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "tfidf=TfidfVectorizer()\n",
    "ti=tfidf.fit_transform(corpus)\n",
    "print(ti)\n",
    "\n",
    "print(\"***************\")\n",
    "\n",
    "features=tfidf.get_feature_names_out()\n",
    "print(features)\n",
    "\n",
    "print(\"***************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b71e113-6da6-41bb-81f4-1d91c1de906c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.3331023155662109\n",
      "  (0, 12)\t0.3331023155662109\n",
      "  (0, 17)\t0.3331023155662109\n",
      "  (0, 13)\t0.23700504099641823\n",
      "  (0, 3)\t0.3331023155662109\n",
      "  (0, 2)\t0.3331023155662109\n",
      "  (0, 14)\t0.3331023155662109\n",
      "  (0, 10)\t0.23700504099641823\n",
      "  (0, 7)\t0.3331023155662109\n",
      "  (0, 4)\t0.3331023155662109\n",
      "  (1, 13)\t0.2144061353375654\n",
      "  (1, 10)\t0.2144061353375654\n",
      "  (1, 9)\t0.3013403421812651\n",
      "  (1, 6)\t0.3013403421812651\n",
      "  (1, 8)\t0.3013403421812651\n",
      "  (1, 5)\t0.3013403421812651\n",
      "  (1, 19)\t0.3013403421812651\n",
      "  (1, 16)\t0.3013403421812651\n",
      "  (1, 15)\t0.3013403421812651\n",
      "  (1, 1)\t0.3013403421812651\n",
      "  (1, 11)\t0.3013403421812651\n",
      "  (1, 18)\t0.3013403421812651\n"
     ]
    }
   ],
   "source": [
    "ti.toarray()\n",
    "print(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49401bf2-25de-4029-ac2e-dfc3919246af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
